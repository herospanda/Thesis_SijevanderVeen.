{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sije91/DRD./blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8DL8lpMEKB3P",
        "colab_type": "code",
        "outputId": "8b2fe14d-635a-4c07-81ec-8626aaecc6dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import pandas as pd \n",
        "import numpy as np  \n",
        "import re  \n",
        "import nltk  \n",
        "from sklearn.datasets import load_files  \n",
        "nltk.download('stopwords')  \n",
        "import pickle  \n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, numpy, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "from keras.preprocessing import text\n",
        "\n",
        "import gensim \n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CSslHtjaUuuj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert labels from string to integer (the numbers are equal to the value number in the gold standard for example 'disgust': 1)"
      ]
    },
    {
      "metadata": {
        "id": "moCK6eIqKC-D",
        "colab_type": "code",
        "outputId": "45621a90-b5fb-4858-c385-5d0270b82dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/DRC_topics.csv\", delimiter = ';')\n",
        "\n",
        "df = df[df['event.message'].notnull()]\n",
        "def get_length(message):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    message_size = len(message)\n",
        "    return int(message_size)\n",
        "\n",
        "convert_string = {'anger': 4, 'disgust': 1, 'fear': 7, 'happiness': 6,'neutral': 3,'sadness': 5,'surprise': 2}\n",
        "\n",
        "def get_integer_emotion(emotion):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    new_integer = convert_string[emotion] \n",
        "    return int(new_integer)\n",
        "\n",
        "df['size_message'] = df['event.message'].apply(get_length)\n",
        "df['emotion_integer'] = df['event.emotion'].apply(get_integer_emotion)\n",
        "df = df[df['size_message'] > 3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_wA3iwkcV2Ul",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get equal number of labels for each class."
      ]
    },
    {
      "metadata": {
        "id": "p-UKfzD3KDhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1 = df['emotion_integer'] == 1\n",
        "df11 = df[df1][0:3700]\n",
        "\n",
        "df2 = df['emotion_integer'] == 2\n",
        "df22 = df[df2][0:3700]\n",
        "\n",
        "df3 = df['emotion_integer'] == 3\n",
        "df33 = df[df3][0:3700]\n",
        "\n",
        "df4 = df['emotion_integer'] == 4\n",
        "df44 = df[df4][0:3700]\n",
        "\n",
        "df5 = df['emotion_integer'] == 5\n",
        "df55 = df[df5][0:3700]\n",
        "\n",
        "df6 = df['emotion_integer'] == 6\n",
        "df66 = df[df6][0:3700]\n",
        "\n",
        "df7 = df['emotion_integer'] == 7\n",
        "df77 = df[df7][0:3700]\n",
        "\n",
        "frames = [df11, df22, df33, df44, df55, df66, df77]\n",
        "df = pd.concat(frames)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KowQrZDoWNyN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stemming method for French data"
      ]
    },
    {
      "metadata": {
        "id": "ci5A-tyNKI8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "\n",
        "from nltk.stem.snowball import FrenchStemmer\n",
        "\n",
        "stemmer = FrenchStemmer()\n",
        "def get_stemming(sen):  \n",
        "    # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(sen))\n",
        "\n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "\n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "\n",
        "    # Removing prefixed 'b'\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "\n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "\n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "\n",
        "    document = [stemmer.stem(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "\n",
        "    return(document)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R3NLa48yKMF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_emo = pd.read_csv(\"/content/French_goldstandard.csv\", delimiter = ',', error_bad_lines=False)\n",
        "\n",
        "df_emo[\"word_french_stem\"] = df_emo[\"word_french\"].apply(get_stemming)\n",
        "\n",
        "df_emo.to_csv('French_goldstandard2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q82MiGdNKKiE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['message_stemmer'] = df['event.message'].apply(get_stemming)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33meI9MidcF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "C7vNsdoqvtJH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate the score for each class based on the goldstandard, the class with the most high score will be used as label."
      ]
    },
    {
      "metadata": {
        "id": "gv2-x-qjKSuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "df = df[0:200000]\n",
        "def get_score(word_list):\n",
        "    split_words = word_list.split(' ')\n",
        "    for word in split_words:\n",
        "        #print(word)\n",
        "        with open('French_goldstandard2.csv') as csvfile:\n",
        "            csv_values = csv.reader(csvfile)\n",
        "            for row in csv_values:\n",
        "                disgust = 0\n",
        "                surprise = 0\n",
        "                neutral = 0\n",
        "                anger = 0\n",
        "                sad = 0\n",
        "                happy = 0\n",
        "                fear = 0 \n",
        "                if str(row[11]) == str(word):\n",
        "                    disgust += float(row[3])\n",
        "                    surprise += float(row[4])\n",
        "                    neutral += float(row[5])\n",
        "                    anger += float(row[6])\n",
        "                    sad += float(row[7])\n",
        "                    happy += float(row[8])\n",
        "                    try:\n",
        "                        fear += float(row[9])  \n",
        "                    except ValueError:\n",
        "                        fear += 0\n",
        "                    scores = [disgust,surprise,neutral,anger,sad,happy,fear]\n",
        "                    scores.append(scores.index(max(scores)))\n",
        "                    return(scores)\n",
        "\n",
        "df['message_score'] = df['message_stemmer'].apply(get_score)\n",
        "df.to_csv('DRC_topics_scores.csv',sep = ';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mjWQgGmKX1r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_scores = pd.read_csv(\"/home/sije/Thesis/DRC_topics_scores.csv\", delimiter = ';')\n",
        "\n",
        "df_scores = df_scores[df_scores.message_score.notnull()]\n",
        "print(len(df_scores))\n",
        "def get_class(score_list):\n",
        "    scores = score_list.split(',')\n",
        "    #print(scores)\n",
        "    return(int(scores[6].replace(']','')) + 1)\n",
        "\n",
        "df_scores['message_class'] = df_scores['message_score'].apply(get_class)    \n",
        "print(df_scores['message_class'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmlOa4cTeGT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1 = df_scores.loc[df_scores['message_class'] == 1]['emotion_integer'][0:1500]\n",
        "\n",
        "df2 = df_scores.loc[df_scores['message_class'] == 2]['emotion_integer'][0:1500]\n",
        "\n",
        "df3 = df_scores.loc[df_scores['message_class'] == 3]['emotion_integer'][0:1500]\n",
        "\n",
        "df4 = df_scores.loc[df_scores['message_class'] == 4]['emotion_integer'][0:1500]\n",
        "\n",
        "df5 = df_scores.loc[df_scores['message_class'] == 5]['emotion_integer'][0:1500]\n",
        "\n",
        "df6 = df_scores.loc[df_scores['message_class'] == 6]['emotion_integer'][0:1500]\n",
        "\n",
        "df7 = df_scores.loc[df_scores['message_class'] == 7]['emotion_integer'][0:1500]\n",
        "\n",
        "frames = [df1, df2, df3, df4, df5, df6, df7]\n",
        "df = pd.concat(frames)\n",
        "print(len(df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gzdkhGhmvU2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df_scores.dropna()\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_scores['message_stemmer'], df_scores['message_class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAQxB0y2viwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpNKMAFIvn4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a count vectorizer object \n",
        "#count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(df['message_stemmer'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(X_train.apply(lambda x: np.str_(x)))\n",
        "xvalid_count =  count_vect.transform(X_test.apply(lambda x: np.str_(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRTg4tVXvruC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['message_stemmer'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(X_train.apply(lambda x: np.str_(x)))\n",
        "xvalid_tfidf =  tfidf_vect.transform(X_test.apply(lambda x: np.str_(x)))\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['message_stemmer'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train.apply(lambda x: np.str_(x)))\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(X_test.apply(lambda x: np.str_(x)))\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['message_stemmer'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_train.apply(lambda x: np.str_(x)))\n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_test.apply(lambda x: np.str_(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5fbLYVxhvv6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    print(confusion_matrix(y_test,predictions))  \n",
        "    print(classification_report(y_test,predictions))  \n",
        "    print(accuracy_score(y_test,predictions))\n",
        "    #return metrics.accuracy_score(predictions, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrfI0eMOv6u7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "print(\"NB, Count Vectors: \")\n",
        "train_model(naive_bayes.MultinomialNB(), xtrain_count, y_train, xvalid_count)\n",
        "\n",
        "\n",
        "# Naive Bayes on Word Level TF IDF Vectors\n",
        "print(\"NB, WordLevel TF-IDF: \")\n",
        "train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xvalid_tfidf)\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "print(\"NB, N-Gram Vectors: \")\n",
        "train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, y_train, xvalid_tfidf_ngram)\n",
        "\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "print(\"NB, CharLevel Vectors: \")\n",
        "train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, y_train, xvalid_tfidf_ngram_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfodhhF4v-KU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Linear Classifier on Count Vectors\n",
        "print(\"LR, Count Vectors: \")\n",
        "train_model(linear_model.LogisticRegression(), xtrain_count, y_train, xvalid_count)\n",
        "\n",
        "\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "print(\"LR, WordLevel TF-IDF: \")\n",
        "train_model(linear_model.LogisticRegression(), xtrain_tfidf, y_train, xvalid_tfidf)\n",
        "\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "print(\"LR, N-Gram Vectors: \")\n",
        "train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, y_train, xvalid_tfidf_ngram)\n",
        "\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "print(\"LR, CharLevel Vectors: \")\n",
        "train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, y_train, xvalid_tfidf_ngram_chars)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AI8dum4BT_Te",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "0PBh0jAbUpKS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}